# 

import os
import io
import re
import tempfile
import base64
import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI
from langchain_community.document_loaders import PyPDFLoader
import fitz
from PIL import Image
import json



# --- í™˜ê²½ ë³€ìˆ˜ ---
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    st.error("OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤. .envì— í‚¤ë¥¼ ë„£ì–´ì£¼ì„¸ìš”.")
    st.stop()
client = OpenAI(api_key=OPENAI_API_KEY)

# --- OCR (gpt-4o ë¹„ì „) ---
def extract_text_with_ocr_pymupdf(pdf_path: str):
    """PyMuPDFë¡œ PDFâ†’ì´ë¯¸ì§€ ë Œë”ë§ í›„ GPT-4o Vision OCR ìˆ˜í–‰"""
    try:
        doc = fitz.open(pdf_path)
        all_texts = []
        for i, page in enumerate(doc, 1):
            pix = page.get_pixmap(dpi=200)
            img = Image.open(io.BytesIO(pix.tobytes("png")))
            buf = io.BytesIO()
            img.save(buf, format="PNG")
            img_b64 = base64.b64encode(buf.getvalue()).decode("utf-8")

            response = client.chat.completions.create(
                model="gpt-4o",
                temperature=0,
                messages=[{
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "ì•„ë˜ ì´ë¯¸ì§€ì—ì„œ ë³´ì´ëŠ” í…ìŠ¤íŠ¸ë¥¼ ê°€ëŠ¥í•œ í•œ ì •í™•íˆ ì¶”ì¶œí•´ì¤˜."},
                        {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{img_b64}"}}
                    ]
                }],
                max_tokens=2048
            )
            text = (response.choices[0].message.content or "").strip()
            all_texts.append(text)
            st.write(f"ğŸ“„ í˜ì´ì§€ {i}/{len(doc)} OCR ì™„ë£Œ")
        return "\n\n".join(all_texts), None
    except Exception as e:
        return "", f"PyMuPDF OCR ì—ëŸ¬: {str(e)}"

# --- PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ---
def extract_text_from_pdf(uploaded_file, use_ocr: bool = False) -> tuple[str, str | None]:
    tmp_path = None
    try:
        try:
            uploaded_file.seek(0)
        except Exception:
            pass

        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
            tmp.write(uploaded_file.read())
            tmp_path = tmp.name

        # 1) í…ìŠ¤íŠ¸ ë ˆì´ì–´ ìš°ì„  ì‹œë„
        try:
            loader = PyPDFLoader(tmp_path)
            pages = loader.load()
        except Exception as e:
            pages = []
            st.write(f"PyPDFLoader ì—ëŸ¬: {e}")

        if not pages:
            if use_ocr:
                return extract_text_with_ocr_pymupdf(tmp_path)
            return "", "PDFì— í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤."

        text_parts = []
        for i, page in enumerate(pages):
            content = (page.page_content or "").strip()
            text_parts.append(content)
            st.write(f"í˜ì´ì§€ {i+1} í…ìŠ¤íŠ¸ ê¸¸ì´: {len(content)} ë¬¸ì")

        result = ("\n\n".join(text_parts)).strip()

        # 2) í…ìŠ¤íŠ¸ê°€ ê±°ì˜ ì—†ìœ¼ë©´ OCR í´ë°±
        if (not result or len(result) < 50) and use_ocr:
            st.info("í…ìŠ¤íŠ¸ê°€ ê±°ì˜ ì—†ì–´ OCRì„ ì‹œë„í•©ë‹ˆë‹¤...")
            return extract_text_with_ocr_pymupdf(tmp_path)

        return result, None

    except Exception as e:
        if use_ocr and tmp_path:
            try:
                return extract_text_with_ocr_pymupdf(tmp_path)
            except Exception:
                pass
        return "", str(e)
    finally:
        if tmp_path and os.path.exists(tmp_path):
            try:
                os.unlink(tmp_path)
            except Exception:
                pass

# --- ì²­í‚¹/ìš”ì•½ ---
def chunk_text(text: str, max_chars: int = 6000) -> list[str]:
    if not text:
        return []
    paragraphs = [p.strip() for p in text.split("\n\n") if p.strip()]
    chunks, buf = [], ""
    for p in paragraphs:
        if len(buf) + len(p) + 2 <= max_chars:
            buf = f"{buf}\n\n{p}" if buf else p
        else:
            chunks.append(buf)
            buf = p
    if buf:
        chunks.append(buf)
    safe_chunks = []
    for c in chunks:
        if len(c) <= max_chars:
            safe_chunks.append(c)
        else:
            for i in range(0, len(c), max_chars):
                safe_chunks.append(c[i : i + max_chars])
    return safe_chunks

# OpenAI SDK í˜¸í™˜ ìœ„í•´ ì›í˜• ìœ ì§€
def gpt_summarize_k5(text: str) -> str:
    prompt = (
        "ë‹¤ìŒ í•™ìŠµ ìë£Œë¥¼ í•œêµ­ì–´ë¡œ **5ì¤„ ì´ë‚´**ë¡œ í•µì‹¬ë§Œ ìš”ì•½í•´ì¤˜.\n"
        "ë¶ˆí•„ìš”í•œ ì˜ˆì‹œëŠ” ë¹¼ê³ , í•µì‹¬ ê°œë…/ì •ì˜/ì‹ ìœ„ì£¼ë¡œ ì •ë¦¬í•´ì¤˜.\n\n"
        f"[ë³¸ë¬¸]\n{text}"
    )
    res = client.chat.completions.create(
        model="gpt-4o",
        temperature=0.2,
        messages=[{"role": "user", "content": prompt}],
    )
    return (res.choices[0].message.content or "").strip()

def summarize_long_text(text: str) -> str:
    chunks = chunk_text(text)
    if not chunks:
        return "ìš”ì•½í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."
    if len(chunks) == 1:
        return gpt_summarize_k5(chunks[0])
    part_summaries = []
    for i, c in enumerate(chunks, 1):
        with st.spinner(f"ì²­í¬ ìš”ì•½ ì¤‘... ({i}/{len(chunks)})"):
            part_summaries.append(gpt_summarize_k5(c))
    joined = "\n\n".join(part_summaries)
    final_prompt = (
        "ì•„ë˜ ë¶€ë¶„ ìš”ì•½ë“¤ì„ **í†µí•©**í•´ì„œ í•œêµ­ì–´ë¡œ **ì •í™•íˆ 5ì¤„ ì´ë‚´**ë¡œ í•µì‹¬ë§Œ ì••ì¶•í•´ì¤˜.\n"
        "ì¤‘ë³µ ì œê±°, ìš©ì–´ í†µì¼, ìˆ˜ì‹/ì •ì˜/í•µì‹¬ ë…¼ì ë§Œ ë‚¨ê²¨.\n\n"
        f"[ë¶€ë¶„ ìš”ì•½]\n{joined}"
    )
    res = client.chat.completions.create(
        model="gpt-4o",
        temperature=0.2,
        messages=[{"role": "user", "content": final_prompt}],
    )
    return (res.choices[0].message.content or "").strip()


# imageë„ ì¸ì‹ ê°€ëŠ¥í•˜ë„ë¡
def detect_figure_heavy_pages(doc):
    pages = []
    for i, page in enumerate(doc):
        # í…ìŠ¤íŠ¸ê°€ ë§¤ìš° ì ê±°ë‚˜ ì´ë¯¸ì§€ ê°œìˆ˜ê°€ ë§ì€ í˜ì´ì§€ë¥¼ ì„ ë³„
        if len(page.get_text().strip()) < 200 or len(page.get_images(full=True)) >= 1:
            pages.append(i)
    return pages

def describe_page_with_gpt4o_image(pix_png_b64: str) -> str:
    res = client.chat.completions.create(
        model="gpt-4o",
        temperature=0.2,
        messages=[{
            "role":"user",
            "content":[
                {"type":"text","text":
                 "ì´ë¯¸ì§€ì˜ ê·¸ë˜í”„/ë„ì‹/í‘œë¥¼ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì¤˜. í•µì‹¬ í¬ì¸íŠ¸ 3~5ê°œ ë¶ˆë¦¿:\n"
                 "- ê·¸ë˜í”„: ì¶• ì˜ë¯¸/ì¶”ì„¸/ìµœëŒ€Â·ìµœì†Œ/ë¹„êµ\n"
                 "- ë„ì‹: ë…¸ë“œ/ê´€ê³„/ì ˆì°¨\n"
                 "- í‘œ: í•µì‹¬ í–‰Â·ì—´ê³¼ ê²°ë¡ \n"},
                {"type":"image_url","image_url":{"url": f"data:image/png;base64,{pix_png_b64}"}}
            ]
        }]
    )
    return (res.choices[0].message.content or "").strip()


def build_qa_context(full_text: str, question: str, max_ctx_chars: int = 16000) -> str:
    """
    ì„ë² ë”© ì—†ì´ ë™ì‘í•˜ëŠ” ë¯¸ë‹ˆ RAG:
    - ë¬¸ì„œë¥¼ ì²­í‚¹ â†’ ì§ˆë¬¸ê³¼ í‚¤ì›Œë“œ ê²¹ì¹˜ëŠ” ì •ë„ë¡œ ìŠ¤ì½”ì–´ë§ â†’ ìƒìœ„ ì²­í¬ë§Œ ëª¨ì•„ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    """
    chunks = chunk_text(full_text, max_chars=3000)  # ì²­í¬ í¬ê¸°(ë¬¸ì ê¸°ì¤€)
    if not chunks:
        return ""

    # ì•„ì£¼ ë‹¨ìˆœí•œ í‚¤ì›Œë“œ ê¸°ë°˜ ìŠ¤ì½”ì–´
    q_tokens = set(question.lower().split())
    scored = []
    for c in chunks:
        c_tokens = set(c.lower().split())
        overlap = len(q_tokens & c_tokens)
        # ë„ˆë¬´ ê¸´ ì²­í¬ëŠ” ì•½ê°„ íŒ¨ë„í‹°
        score = overlap - 0.00001 * len(c)
        scored.append((score, c))

    # ìƒìœ„ 3~4ê°œ ì»¨í…ìŠ¤íŠ¸ë¡œ ë¬¶ê¸°
    top_ctx = "\n\n---\n\n".join(
        [c for _, c in sorted(scored, key=lambda x: x[0], reverse=True)[:4]]
    )
    return top_ctx[:max_ctx_chars]


def answer_from_doc(full_text: str, question: str) -> str:
    """
    ë¬¸ì„œ ê·¼ê±° ê¸°ë°˜ìœ¼ë¡œë§Œ ë‹µë³€. ê·¼ê±° ì—†ìœ¼ë©´ 'ë¬¸ì„œ ê·¼ê±°ë¡œëŠ” ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'ë¡œ ì‘ë‹µ.
    """
    context = build_qa_context(full_text, question)
    system = (
        "ë„ˆëŠ” ë¬¸ì„œ ê¸°ë°˜ Q&A ì¡°êµë‹¤. ë°˜ë“œì‹œ ì œê³µëœ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ ì•ˆì—ì„œë§Œ ë‹µí•˜ë¼. "
        "ë¬¸ì„œì— ê·¼ê±°ê°€ ì—†ìœ¼ë©´ 'ë¬¸ì„œ ê·¼ê±°ë¡œëŠ” ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'ë¼ê³  ë‹µí•œë‹¤. "
        "í—ˆêµ¬ ìƒì„± ê¸ˆì§€, ê°„ê²°í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ë‹µí•˜ë¼."
    )
    user = f"[ì»¨í…ìŠ¤íŠ¸]\n{context}\n\n[ì§ˆë¬¸]\n{question}"
    res = client.chat.completions.create(
        model="gpt-4o",
        temperature=0.1,
        messages=[
            {"role": "system", "content": system},
            {"role": "user", "content": user},
        ],
    )
    return (res.choices[0].message.content or "").strip()


def _extract_json_block(text: str) -> str:
    """ëª¨ë¸ì´ JSON ì™¸ í…ìŠ¤íŠ¸ë¥¼ ì„ì–´ì¤„ ë•Œ { ... } ë¸”ë¡ë§Œ ì•ˆì „ ì¶”ì¶œ"""
    m = re.search(r"\{.*\}", text, flags=re.S)
    if not m:
        raise ValueError("ëª¨ë¸ ì‘ë‹µì—ì„œ JSON ë¸”ë¡ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    return m.group(0)


def extract_keypoints_for_quiz(full_text: str) -> str:
    """
    ê¸´ ë¬¸ì„œì—ì„œ ë¬¸ì œê±°ë¦¬ê°€ ë  í•µì‹¬ í¬ì¸íŠ¸ë¥¼ ë¨¼ì € ë½‘ì•„ë‚¸ ë’¤(ì²­í‚¹â†’ë¶€ë¶„ìš”ì•½â†’í†µí•©),
    ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì œë¥¼ ìƒì„±í•©ë‹ˆë‹¤. (ì •í™•ë„ â†‘)
    """
    chunks = chunk_text(full_text, max_chars=4000)
    if not chunks:
        return ""
    bullets = []
    for i, c in enumerate(chunks, start=1):
        with st.spinner(f"ë¬¸ì„œ í‚¤í¬ì¸íŠ¸ ìˆ˜ì§‘ ì¤‘... ({i}/{len(chunks)})"):
            prompt = (
                "ë„ˆëŠ” ëŒ€í•™ êµì¬ë¡œë¶€í„° ë¬¸ì œê±°ë¦¬ê°€ ë  'í•µì‹¬ í‚¤í¬ì¸íŠ¸'ë¥¼ ë½‘ëŠ” ì¡°êµë‹¤.\n"
                "ì•„ë˜ ë³¸ë¬¸ì—ì„œ ì •ì˜/í•µì‹¬ ê°œë…/ì¤‘ìš” ê·œì¹™/ì˜ˆì™¸/ìš©ì–´ë¥¼ í•œêµ­ì–´ ë¶ˆë¦¿ 5~8ê°œë¡œë§Œ ì •ë¦¬í•´ë¼.\n\n"
                f"[ë³¸ë¬¸]\n{c}"
            )
            r = client.chat.completions.create(
                model="gpt-4o",
                temperature=0.2,
                messages=[{"role": "user", "content": prompt}],
            )
            bullets.append((r.choices[0].message.content or "").strip())
    merged = "\n\n".join(bullets)

    reducer = (
        "ì•„ë˜ ë¶€ë¶„ í‚¤í¬ì¸íŠ¸ ëª©ë¡ì„ ì¤‘ë³µ ì œê±°í•˜ê³ , ìš©ì–´ë¥¼ í†µì¼í•´ í•œêµ­ì–´ë¡œ 15~25ê°œ í•µì‹¬ í‚¤í¬ì¸íŠ¸ë§Œ ë‚¨ê²¨ë¼.\n"
        "ë¶ˆí•„ìš”í•œ ì˜ˆì‹œëŠ” ì œì™¸í•˜ê³  'ì •ì˜/ì›ë¦¬/ê·œì¹™/êµ¬ì¡°/ì ˆì°¨' ì¤‘ì‹¬ìœ¼ë¡œ ì¬ì •ë¦¬í•˜ë¼.\n\n"
        f"[ë¶€ë¶„ í‚¤í¬ì¸íŠ¸]\n{merged}"
    )
    r2 = client.chat.completions.create(
        model="gpt-4o",
        temperature=0.2,
        messages=[{"role": "user", "content": reducer}],
    )
    return (r2.choices[0].message.content or "").strip()


def generate_quiz_from_doc(full_text: str, num_items: int = 4) -> dict:
    """
    ì „ì²´ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°ê´€ì‹/ì£¼ê´€ì‹ ë¬¸ì œ ì´ 3~5ë¬¸í•­ ìƒì„±.
    - keypointsë¥¼ ë¨¼ì € ë§Œë“¤ê³ , ê·¸ê±¸ ê·¼ê±°ë¡œ ë¬¸ì œë¥¼ ìš”êµ¬í•´ ì •í™•ë„ â†‘
    - ì¶œë ¥ì€ ì—„ê²©í•œ JSON ìŠ¤í‚¤ë§ˆë¡œ ê°•ì œ
    """
    num_items = max(3, min(5, int(num_items)))
    keypoints = extract_keypoints_for_quiz(full_text)
    prompt = f"""
ë„ˆëŠ” ëŒ€í•™ êµì¬ ê¸°ë°˜ í€´ì¦ˆë¥¼ ë§Œë“œëŠ” ì¡°êµë‹¤.
[í‚¤í¬ì¸íŠ¸]ë¥¼ ë°˜ë“œì‹œ ê·¼ê±°ë¡œ í•˜ì—¬ ê°ê´€ì‹/ì£¼ê´€ì‹ í•©ì³ ì´ {num_items}ë¬¸í•­ì„ ìƒì„±í•˜ë¼.
ì¡°ê±´:
- ê°ê´€ì‹(MCQ): ë³´ê¸° 4ê°œ, ì˜¤ì§ í•˜ë‚˜ì˜ ì •ë‹µ. ì •ë‹µ ì¸ë±ìŠ¤(answer_index, 0~3) í¬í•¨.
- ì£¼ê´€ì‹(short): ê¸°ì¤€ ì •ë‹µ(answer) ë¬¸ì¥ê³¼ ì±„ì  í‚¤ì›Œë“œ(rubric_keywords, 3~6ê°œ) í¬í•¨.
- ê° ë¬¸í•­ì—ëŠ” ê°„ë‹¨í•œ í•œêµ­ì–´ í•´ì„¤(explanation)ì„ í¬í•¨.
- JSONë§Œ ì¶œë ¥. ì—¬ë¶„ í…ìŠ¤íŠ¸ ê¸ˆì§€.

ì¶œë ¥ ìŠ¤í‚¤ë§ˆ(JSON) ì˜ˆ:
{{
  "items": [
    {{
      "type": "mcq",
      "question": "ë¬¸ì œë¬¸ì¥",
      "options": ["ë³´ê¸°1","ë³´ê¸°2","ë³´ê¸°3","ë³´ê¸°4"],
      "answer_index": 1,
      "explanation": "ì™œ ì •ë‹µì¸ì§€ í•œë‘ ë¬¸ì¥"
    }},
    {{
      "type": "short",
      "question": "ì„œìˆ í˜• ë¬¸ì œë¬¸ì¥",
      "answer": "ê¸°ì¤€ ì •ë‹µ(ë¬¸ì¥)",
      "rubric_keywords": ["í‚¤ì›Œë“œ1","í‚¤ì›Œë“œ2","í‚¤ì›Œë“œ3"],
      "explanation": "ì±„ì  ê¸°ì¤€ì— ëŒ€í•œ ê°„ë‹¨ ì„¤ëª…"
    }}
  ]
}}

[í‚¤í¬ì¸íŠ¸]
{keypoints}
"""
    r = client.chat.completions.create(
        model="gpt-4o",
        temperature=0.2,
        messages=[{"role": "user", "content": prompt}],
    )
    raw = (r.choices[0].message.content or "").strip()
    data = json.loads(_extract_json_block(raw))

    # ê°„ë‹¨ ì •í•©ì„± ì²´í¬ ë° ì˜ë¦° í•­ëª© ë°©ì–´
    if not isinstance(data, dict) or "items" not in data:
        raise ValueError("í€´ì¦ˆ JSON í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    fixed = []
    for it in data["items"][:num_items]:
        if it.get("type") == "mcq":
            if "options" in it and isinstance(it["options"], list) and len(it["options"]) == 4 and "answer_index" in it:
                fixed.append(it)
        elif it.get("type") == "short":
            if "answer" in it and "rubric_keywords" in it:
                fixed.append(it)
    return {"items": fixed}


def grade_quiz(quiz: dict, user_answers: dict) -> dict:
    """
    ì‚¬ìš©ìì˜ ë‹µì•ˆì„ ì±„ì í•˜ê³  ì ìˆ˜/ì˜¤ë‹µëª©ë¡ì„ ë°˜í™˜.
    - MCQ: ì •ë‹µ ì¸ë±ìŠ¤ ì¼ì¹˜ ì—¬ë¶€
    - Short: rubric_keywords ë§¤ì¹­ ë¹„ìœ¨ë¡œ ê°„ë‹¨ ì±„ì (0~1)
    """
    results = []
    correct_count = 0

    for idx, item in enumerate(quiz.get("items", [])):
        u = user_answers.get(idx)
        r = {"index": idx, "type": item["type"], "is_correct": False, "score": 0.0}

        if item["type"] == "mcq":
            gt = int(item["answer_index"])
            r["user"] = u if isinstance(u, int) else None
            r["gt"] = gt
            if r["user"] is not None and r["user"] == gt:
                r["is_correct"] = True
                r["score"] = 1.0

        elif item["type"] == "short":
            gt = item.get("answer", "")
            rub = [k.lower() for k in item.get("rubric_keywords", [])]
            utext = (u or "").strip().lower()
            hit = sum(1 for k in rub if k in utext)
            ratio = hit / max(1, len(rub))
            r["user"] = u or ""
            r["gt"] = gt
            r["rubric_hit"] = hit
            r["rubric_total"] = len(rub)
            r["score"] = round(ratio, 2)
            # ê¸°ì¤€: í‚¤ì›Œë“œ ì ˆë°˜ ì´ìƒ í¬í•¨ ì‹œ ì •ë‹µ ì²˜ë¦¬(ê°„ë‹¨ ê¸°ì¤€)
            r["is_correct"] = ratio >= 0.5

        if r["is_correct"]:
            correct_count += 1
        results.append(r)

    return {
        "results": results,
        "total": len(quiz.get("items", [])),
        "correct": correct_count,
        "accuracy": (correct_count / max(1, len(results))) if results else 0.0,
    }


def llm_feedback_for_wrong_answer(item: dict, user_answer: str) -> str:
    """
    ì˜¤ë‹µ/ë¶€ë¶„ì •ë‹µì— ëŒ€í•´ GPTê°€ ì¹œì ˆí•œ í”¼ë“œë°±ì„ ìƒì„±.
    - ê·¼ê±°: ë¬¸ì œë¬¸/ì •ë‹µ/ë£¨ë¸Œë¦­/í•´ì„¤
    - ì¶œë ¥: ì™œ í‹€ë ¸ëŠ”ì§€, ì±„ì  ê¸°ì¤€ê³¼ ë¹„êµ, ë³´ì™„ í¬ì¸íŠ¸ 3~5ì¤„
    """
    q = item.get("question", "")
    if item["type"] == "mcq":
        options = ", ".join(item.get("options", []))
        gt_idx = int(item.get("answer_index", 0))
        gt_text = item.get("options", [""])[gt_idx] if item.get("options") else ""
        exp = item.get("explanation", "")
        user = f"(ì„ íƒì§€ ì¸ë±ìŠ¤: {user_answer})"
        prompt = f"""
[ë¬¸ì œ]
{q}
[ë³´ê¸°]
{options}

[ë‹¹ì‹ ì˜ ë‹µ]
{user}

[ì •ë‹µ]
{gt_idx}ë²ˆ: {gt_text}

[ê³µì‹ í•´ì„¤]
{exp}

ìš”êµ¬ì‚¬í•­:
- ì™œ í‹€ë ¸ëŠ”ì§€ í•µì‹¬ ê·¼ê±° 1~2ê°œ
- ì •ë‹µì´ ë§ëŠ” ì´ìœ  1~2ê°œ
- ë‹¤ìŒ ê³µë¶€ í¬ì¸íŠ¸ 2~3ê°œ (ë¶ˆë¦¿)
- í•œêµ­ì–´ 5ì¤„ ì´ë‚´
"""
    else:
        gt = item.get("answer", "")
        rub = ", ".join(item.get("rubric_keywords", []))
        exp = item.get("explanation", "")
        user = user_answer or ""
        prompt = f"""
[ì„œìˆ í˜• ë¬¸ì œ]
{q}

[ë‹¹ì‹ ì˜ ë‹µ]
{user}

[ê¸°ì¤€ ì •ë‹µ]
{gt}

[ì±„ì  í‚¤ì›Œë“œ]
{rub}

[ê³µì‹ í•´ì„¤]
{exp}

ìš”êµ¬ì‚¬í•­:
- ì±„ì  í‚¤ì›Œë“œ ê¸°ì¤€ìœ¼ë¡œ ë¬´ì—‡ì´ ë¶€ì¡±í–ˆëŠ”ì§€
- ì •ë‹µì˜ í•µì‹¬ í‘œí˜„ì„ ì–´ë–»ê²Œ í¬í•¨í•´ì•¼ í•˜ëŠ”ì§€
- ë³´ì™„ í¬ì¸íŠ¸ 2~3ê°œ (ë¶ˆë¦¿)
- í•œêµ­ì–´ 5ì¤„ ì´ë‚´
"""

    res = client.chat.completions.create(
        model="gpt-4o",
        temperature=0.2,
        messages=[{"role": "user", "content": prompt}],
    )
    return (res.choices[0].message.content or "").strip()












# --- UI ---
st.set_page_config(page_title="í•™ì  ë§ˆìŠ¤í„° - PDF ìš”ì•½", page_icon="ğŸ“", layout="centered")
st.title("ğŸ“ í•™ì  ë§ˆìŠ¤í„° â€” PDF í†µí•© ìš”ì•½(5ì¤„)")
st.caption("ì—¬ëŸ¬ PDF ì—…ë¡œë“œ â†’ í…ìŠ¤íŠ¸ ì¶”ì¶œ(OCR ì„ íƒ) â†’ í†µí•© 5ì¤„ ìš”ì•½")

# 1) ì˜µì…˜ ë¨¼ì €
use_ocr = st.checkbox("OCR ì‚¬ìš© (ì´ë¯¸ì§€/ìŠ¤ìº”ë³¸ PDFì¸ ê²½ìš°)", value=False)
use_figures = st.checkbox("ê·¸ë¦¼/ê·¸ë˜í”„ ìš”ì•½ë„ ë°˜ì˜", value=False)


# 2) ë‹¤ì¤‘ ì—…ë¡œë“œ
uploaded_files = st.file_uploader(
    "PDF íŒŒì¼ì„ ì—¬ëŸ¬ ê°œ ì—…ë¡œë“œí•˜ì„¸ìš”",
    type=["pdf"],
    accept_multiple_files=True
)

# 3) ì‹¤í–‰ ë²„íŠ¼
go = st.button("í†µí•© ìš”ì•½í•˜ê¸°", type="primary", disabled=not uploaded_files)

if go:
    all_texts = []
    for file in uploaded_files:
        with st.spinner(f"{file.name} ì²˜ë¦¬ ì¤‘..."):
            text, error = extract_text_from_pdf(file, use_ocr=use_ocr)
            if error:
                st.error(f"{file.name} ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {error}")
            elif not text:
                st.warning(f"{file.name}: í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            else:
                all_texts.append(text)

    # 1) ì—¬ëŸ¬ PDF í…ìŠ¤íŠ¸ í•©ì¹˜ê¸°
    merged_text = "\n\n".join([t for t in all_texts if t])

    # 2) (ì˜µì…˜) ê·¸ë¦¼/ê·¸ë˜í”„ ìš”ì•½ ë°˜ì˜
    #    - use_figures ì²´í¬ë°•ìŠ¤ë¥¼ UI ìƒë‹¨ì— ì¶”ê°€í•´ë‘” ìƒíƒœì—¬ì•¼ í•©ë‹ˆë‹¤.
    if merged_text and 'use_figures' in locals() and use_figures:
        try:
            # ì—¬ëŸ¬ íŒŒì¼ ì¤‘ ì²« ë²ˆì§¸ PDFë§Œ ì˜ˆì‹œë¡œ ì²˜ë¦¬ (ì›í•˜ë©´ for ë£¨í”„ë¡œ ëª¨ë‘ ì²˜ë¦¬ ê°€ëŠ¥)
            first_file = uploaded_files[0]
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
                first_file.seek(0)
                tmp.write(first_file.read())
                pdf_path = tmp.name

            doc = fitz.open(pdf_path)
            cand_pages = detect_figure_heavy_pages(doc)  # í…ìŠ¤íŠ¸ ì ê±°ë‚˜ ì´ë¯¸ì§€ ë§ì€ í˜ì´ì§€
            figure_bullets = []

            # ê³¼ê¸ˆ/ì†ë„ ì ˆì•½: ìµœëŒ€ 5í˜ì´ì§€ê¹Œì§€ë§Œ ë¶„ì„
            for idx in cand_pages[:5]:
                page = doc.load_page(idx)
                pix = page.get_pixmap(dpi=200)

                buf = io.BytesIO()
                Image.open(io.BytesIO(pix.tobytes("png"))).save(buf, format="PNG")
                b64 = base64.b64encode(buf.getvalue()).decode("utf-8")

                with st.spinner(f"ê·¸ë¦¼/ê·¸ë˜í”„ ë¶„ì„ ì¤‘... (p.{idx+1})"):
                    desc = describe_page_with_gpt4o_image(b64)
                if desc:
                    figure_bullets.append(f"[p.{idx+1}] {desc}")

            if figure_bullets:
                merged_text += "\n\n[ê·¸ë¦¼/ê·¸ë˜í”„ ìš”ì•½]\n" + "\n".join(figure_bullets)
                st.info(f"ê·¸ë¦¼ ìš”ì•½ {len(figure_bullets)}ê±´ì„ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.warning(f"ê·¸ë¦¼ ìš”ì•½ ì²˜ë¦¬ ì¤‘ ë¬¸ì œ ë°œìƒ: {e}")

    # 3) ìµœì¢… ì²˜ë¦¬
    if not merged_text:
        st.error("ëª¨ë“  íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    else:
        st.session_state["doc_text"] = merged_text
        with st.spinner("ì „ì²´ ë¬¸ì„œ í†µí•© ìš”ì•½ ì¤‘..."):
            summary = summarize_long_text(merged_text)
        st.subheader("âœ… í†µí•© 5ì¤„ ìš”ì•½")
        st.write(summary)
        with st.expander("í†µí•© ì›ë¬¸(ì¼ë¶€) ë³´ê¸°"):
            st.text(merged_text[:100000])


# st.markdown("---")
# st.subheader("ğŸ’¬ ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸/ë‹µë³€ (Q&A)")

# question = st.text_input("ë¬¸ì„œì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ì§ˆë¬¸í•˜ì„¸ìš”")
# ask_btn = st.button("ì§ˆë¬¸í•˜ê¸°", disabled=not question)

# if ask_btn:
#     doc_text = st.session_state.get("doc_text")
#     if not doc_text:
#         st.warning("ë¨¼ì € PDFë¥¼ ì—…ë¡œë“œí•˜ê³  í†µí•© ìš”ì•½(í…ìŠ¤íŠ¸ ì¶”ì¶œ)ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
#     else:
#         with st.spinner("ë¬¸ì„œì—ì„œ ë‹µì„ ì°¾ëŠ” ì¤‘..."):
#             answer = answer_from_doc(doc_text, question)
#         st.success("ë‹µë³€")
#         st.write(answer)

#         # (ì„ íƒ) ëª¨ë¸ì— ì „ë‹¬í•œ ì»¨í…ìŠ¤íŠ¸ ì¼ë¶€ í™•ì¸ìš©
#         with st.expander("ëª¨ë¸ì— ì „ë‹¬ëœ ì»¨í…ìŠ¤íŠ¸(ì¼ë¶€) ë³´ê¸°"):
#             st.text(build_qa_context(doc_text, question)[:8000])


# st.markdown("---")
# st.subheader("ğŸ“ ë¬¸ì„œ ê¸°ë°˜ ë¬¸ì œ ìƒì„± (ê°ê´€ì‹/ì£¼ê´€ì‹)")

# n_items = st.slider("ë¬¸í•­ ìˆ˜", 3, 5, 4, 1)
# gen_btn = st.button("ë¬¸ì œ ìƒì„±í•˜ê¸°", type="primary")

# if gen_btn:
#     doc_text = st.session_state.get("doc_text")
#     if not doc_text:
#         st.warning("ë¨¼ì € PDFë¥¼ ì—…ë¡œë“œí•˜ê³  í†µí•© ìš”ì•½(í…ìŠ¤íŠ¸ ì¶”ì¶œ)ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
#     else:
#         try:
#             with st.spinner("ë¬¸ì„œ ì „ì²´ë¥¼ ë¶„ì„í•˜ê³  ë¬¸ì œë¥¼ ìƒì„± ì¤‘..."):
#                 quiz = generate_quiz_from_doc(doc_text, num_items=n_items)

#             st.success("ë¬¸ì œ ìƒì„± ì™„ë£Œ")
#             for idx, item in enumerate(quiz["items"], start=1):
#                 st.markdown(f"**Q{idx}. {item['question']}**")
#                 if item["type"] == "mcq":
#                     st.write(f"- ë³´ê¸°: {', '.join(item['options'])}")
#                     st.write(f"- ì •ë‹µ ì¸ë±ìŠ¤: {item['answer_index']}")
#                 else:
#                     st.write(f"- ê¸°ì¤€ì •ë‹µ: {item['answer']}")
#                     st.write(f"- ì±„ì í‚¤ì›Œë“œ: {', '.join(item['rubric_keywords'])}")
#                 st.caption(f"í•´ì„¤: {item.get('explanation','(ì—†ìŒ)')}")

#             # JSON ë‹¤ìš´ë¡œë“œ
#             st.download_button(
#                 "í€´ì¦ˆ JSON ë‹¤ìš´ë¡œë“œ",
#                 data=json.dumps(quiz, ensure_ascii=False, indent=2),
#                 file_name="quiz.json",
#                 mime="application/json",
#             )
#         except Exception as e:
#             st.error(f"ë¬¸ì œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")


#############


st.markdown("---")
st.subheader("ğŸ“ ë¬¸ì„œ ê¸°ë°˜ ë¬¸ì œ ìƒì„± â†’ ì‚¬ìš©ì í’€ì´ â†’ ì±„ì /í”¼ë“œë°±")

# 1) ë¬¸ì œ ìƒì„±
colA, colB = st.columns([2,1])
with colA:
    n_items = st.slider("ë¬¸í•­ ìˆ˜", 3, 5, 4, 1)
with colB:
    gen_btn = st.button("ë¬¸ì œ ìƒì„±í•˜ê¸°", type="primary")

if gen_btn:
    doc_text = st.session_state.get("doc_text")
    if not doc_text:
        st.warning("ë¨¼ì € PDFë¥¼ ì—…ë¡œë“œí•˜ê³  í†µí•© ìš”ì•½(í…ìŠ¤íŠ¸ ì¶”ì¶œ)ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
    else:
        with st.spinner("ë¬¸ì„œ ì „ì²´ë¥¼ ë¶„ì„í•˜ê³  ë¬¸ì œë¥¼ ìƒì„± ì¤‘..."):
            quiz = generate_quiz_from_doc(doc_text, num_items=n_items)
        # ì •ë‹µì€ ì„¸ì…˜ì—ë§Œ ì €ì¥(í™”ë©´ì— ë…¸ì¶œ X)
        st.session_state["quiz"] = quiz
        st.session_state["graded"] = False
        st.session_state["user_answers"] = {}
        st.success("ë¬¸ì œ ìƒì„± ì™„ë£Œ! ì•„ë˜ì—ì„œ í’€ì´ í›„ ì±„ì  ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

# 2) ì‚¬ìš©ì í’€ì´ í¼
quiz = st.session_state.get("quiz")
if quiz and not st.session_state.get("graded"):
    st.markdown("#### âœï¸ ì§€ê¸ˆë¶€í„° ë‹µì„ ì…ë ¥í•˜ì„¸ìš”")
    ua = st.session_state.get("user_answers", {})

    for idx, item in enumerate(quiz["items"]):
        st.markdown(f"**Q{idx+1}. {item['question']}**")

        if item["type"] == "mcq":
            options = item.get("options", [])
            ua[idx] = st.radio(
                "ì„ íƒì§€",
                options=[f"{i}. {opt}" for i, opt in enumerate(options)],
                index=ua.get(idx, None) if isinstance(ua.get(idx, None), int) else 0,
                key=f"mcq_{idx}",
            )
            # ë¼ë²¨ì„ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
            try:
                ua[idx] = int(ua[idx].split(".")[0])
            except Exception:
                ua[idx] = None

        else:  # short
            ua[idx] = st.text_area(
                "ì„œìˆ í˜• ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”",
                value=ua.get(idx, ""),
                key=f"short_{idx}",
                height=100,
            )
        st.markdown("---")

    st.session_state["user_answers"] = ua
    submit = st.button("ì±„ì í•˜ê¸°", type="primary")
    if submit:
        with st.spinner("ì±„ì  ì¤‘..."):
            report = grade_quiz(quiz, ua)
        st.session_state["report"] = report
        st.session_state["graded"] = True
        st.success(f"ì±„ì  ì™„ë£Œ! ì •ë‹µ {report['correct']} / {report['total']} (ì •í™•ë„ {round(report['accuracy']*100,1)}%)")

# 3) ì±„ì  ê²°ê³¼ + ì •ë‹µ/í•´ì„¤ ê³µê°œ + ì˜¤ë‹µ í”¼ë“œë°±
if quiz and st.session_state.get("graded"):
    report = st.session_state.get("report", {})
    ua = st.session_state.get("user_answers", {})

    st.markdown("#### ğŸ“Š ì±„ì  ê²°ê³¼")
    st.write(f"ì •ë‹µ {report.get('correct',0)} / {report.get('total',0)}  "
             f"(ì •í™•ë„ {round(report.get('accuracy',0)*100,1)}%)")

    st.markdown("#### âœ… ì •ë‹µ/í•´ì„¤ ë° í”¼ë“œë°±")
    for r in report.get("results", []):
        item = quiz["items"][r["index"]]
        st.markdown(f"**Q{r['index']+1}. {item['question']}**")

        if item["type"] == "mcq":
            st.write(f"- ë‹¹ì‹ ì˜ ë‹µ: {ua.get(r['index'])}")
            st.write(f"- ì •ë‹µ ì¸ë±ìŠ¤: {item['answer_index']}")
            st.caption(f"í•´ì„¤: {item.get('explanation','(ì—†ìŒ)')}")
            if not r["is_correct"]:
                fb = llm_feedback_for_wrong_answer(item, str(ua.get(r['index'])))
                with st.expander("AI í”¼ë“œë°± ë³´ê¸°"):
                    st.write(fb)

        else:  # short
            st.write(f"- ë‹¹ì‹ ì˜ ë‹µ: {ua.get(r['index'], '')}")
            st.write(f"- ê¸°ì¤€ ì •ë‹µ: {item.get('answer','')}")
            st.write(f"- ì±„ì í‚¤ì›Œë“œ: {', '.join(item.get('rubric_keywords', []))}")
            st.caption(f"í•´ì„¤: {item.get('explanation','(ì—†ìŒ)')}")
            st.write(f"- í‚¤ì›Œë“œ ë§¤ì¹­: {r.get('rubric_hit',0)} / {r.get('rubric_total',0)}")
            if not r["is_correct"]:
                fb = llm_feedback_for_wrong_answer(item, ua.get(r['index'], ''))
                with st.expander("AI í”¼ë“œë°± ë³´ê¸°"):
                    st.write(fb)

    # (ì„ íƒ) ë‹¤ì‹œ í’€ê¸°/ìƒˆ ë¬¸ì œ ë§Œë“¤ê¸°
    st.markdown("---")
    col1, col2 = st.columns(2)
    if col1.button("ë‹¤ì‹œ í’€ê¸°"):
        st.session_state["graded"] = False
    if col2.button("ìƒˆ ë¬¸ì œ ìƒì„±"):
        for k in ["quiz", "graded", "user_answers", "report"]:
            st.session_state.pop(k, None)
